Based on Hugging Face code found here:

https://github.com/huggingface/transformers


Set up AWS p2 instance.  Connect via ssh with .pem file:

ssh -i aws_gputest_1.pem ubuntu@3.17.70.161

source activate pytorch_p36


Sanity check:  usually not needed, but can test if PyTorch is using GPU:

python3

import torch
torch.cuda.current_device()
torch.cuda.device(0)
torch.cuda.device_count()
torch.cuda.get_device_name(0)
torch.cuda.is_available()


pip install --upgrade pip

pip install transformers

git clone https://github.com/huggingface/transformers.git

git clone https://github.com/jasonrohrer/jason-rohrer.git

cd jason-rohrer/ai/text/transformersMod

python ./run_generation.py --model_type=gpt2 --length=20 --model_name_or_path=gpt2

python ./run_generation.py --model_type=gpt2 --length=200 --model_name_or_path=gpt2-xl


python ./run_generation.py --model_type=gpt2 --length=20 --model_name_or_path=gpt2-xl --out_file=out.txt --in_file=sampleInputShort.txt --gen_words=500


